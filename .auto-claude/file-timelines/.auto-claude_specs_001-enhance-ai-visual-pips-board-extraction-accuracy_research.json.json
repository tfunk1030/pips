{
  "file_path": ".auto-claude/specs/001-enhance-ai-visual-pips-board-extraction-accuracy/research.json",
  "main_branch_history": [],
  "task_views": {
    "005-add-image-stats-diagnostic-endpoint": {
      "task_id": "005-add-image-stats-diagnostic-endpoint",
      "branch_point": {
        "commit_hash": "faf3f69f9b2794c6a85ffd2581461d3d68bdf8ef",
        "content": "",
        "timestamp": "2025-12-22T03:09:16.372053"
      },
      "worktree_state": {
        "content": "{\n  \"integrations_researched\": [\n    {\n      \"name\": \"Expo SDK\",\n      \"type\": \"framework\",\n      \"verified_package\": {\n        \"name\": \"expo\",\n        \"install_command\": \"npx create-expo-app\",\n        \"version\": \"~54.0.30\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import * as ImagePicker from 'expo-image-picker'\",\n          \"import * as FileSystem from 'expo-file-system'\",\n          \"import { Image } from 'expo-image'\"\n        ],\n        \"initialization\": \"npx expo start\",\n        \"key_functions\": [\n          \"ImagePicker.launchImageLibraryAsync({ mediaTypes: ['images'], allowsEditing: true, quality: 1 })\",\n          \"ImagePicker.requestMediaLibraryPermissionsAsync()\",\n          \"FileSystem.readAsStringAsync(uri, { encoding: FileSystem.EncodingType.Base64 })\"\n        ],\n        \"verified_against\": \"Context7 MCP: /expo/expo, /websites/expo_dev_versions_v54_0_0\"\n      },\n      \"configuration\": {\n        \"env_vars\": [],\n        \"config_files\": [\"app.json\", \"eas.json\"],\n        \"dependencies\": [\n          \"expo-image-picker\",\n          \"expo-file-system\",\n          \"expo-image-manipulator\"\n        ]\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false,\n        \"docker_image\": null,\n        \"ports\": [8081, 19000, 19001],\n        \"volumes\": []\n      },\n      \"gotchas\": [\n        \"ImagePicker result.assets[0].uri contains the selected image URI\",\n        \"No permissions request needed for launching image library on most platforms\",\n        \"For videos on iOS with allowsEditing: false and videoExportPreset: 'Passthrough', manually request permissions\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /expo/expo\",\n        \"https://docs.expo.dev/versions/v54.0.0/sdk/imagepicker/\"\n      ]\n    },\n    {\n      \"name\": \"React Native SVG\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"react-native-svg\",\n        \"install_command\": \"npx expo install react-native-svg\",\n        \"version\": \"15.12.1\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import Svg, { Path, Rect, Circle, G, Text } from 'react-native-svg'\"\n        ],\n        \"initialization\": \"No initialization needed, import and use components directly\",\n        \"key_functions\": [\n          \"<Svg width={width} height={height} viewBox={viewBox}>\",\n          \"<Path d={pathData} fill={color} stroke={strokeColor} />\",\n          \"<Rect x={x} y={y} width={w} height={h} />\",\n          \"<Circle cx={cx} cy={cy} r={radius} />\"\n        ],\n        \"verified_against\": \"Context7 MCP: /software-mansion/react-native-svg\"\n      },\n      \"configuration\": {\n        \"env_vars\": [],\n        \"config_files\": [],\n        \"dependencies\": []\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false\n      },\n      \"gotchas\": [\n        \"Supports most SVG elements and properties\",\n        \"Works with iOS, Android, macOS, Windows, and web\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /software-mansion/react-native-svg\"\n      ]\n    },\n    {\n      \"name\": \"Zod\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"zod\",\n        \"install_command\": \"npm install zod\",\n        \"version\": \"^4.2.1\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import { z } from 'zod'\",\n          \"import * as z from 'zod'\"\n        ],\n        \"initialization\": \"const schema = z.object({ ... })\",\n        \"key_functions\": [\n          \"z.object({ field: z.string() })\",\n          \"z.array(z.string())\",\n          \"z.enum(['option1', 'option2'])\",\n          \"schema.parse(data)\",\n          \"schema.safeParse(data)\",\n          \"z.string().min(1).max(100)\",\n          \"z.number().int().positive()\"\n        ],\n        \"verified_against\": \"Context7 MCP: /colinhacks/zod\"\n      },\n      \"configuration\": {\n        \"env_vars\": [],\n        \"config_files\": [],\n        \"dependencies\": []\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false\n      },\n      \"gotchas\": [\n        \"parse() throws ZodError on validation failure\",\n        \"safeParse() returns { success: boolean, data?, error? } without throwing\",\n        \"Zod 4 has significant performance improvements over v3\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /colinhacks/zod\",\n        \"https://zod.dev\"\n      ]\n    },\n    {\n      \"name\": \"OpenAI API\",\n      \"type\": \"service\",\n      \"verified_package\": {\n        \"name\": \"openai\",\n        \"install_command\": \"npm install openai\",\n        \"version\": \"latest\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import OpenAI from 'openai'\"\n        ],\n        \"initialization\": \"const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })\",\n        \"key_functions\": [\n          \"openai.chat.completions.create({ model, messages, max_tokens })\",\n          \"openai.responses.create({ model, input })\",\n          \"openai.files.create({ file, purpose: 'vision' })\"\n        ],\n        \"verified_against\": \"Context7 MCP: /websites/platform_openai\"\n      },\n      \"configuration\": {\n        \"env_vars\": [\"OPENAI_API_KEY\"],\n        \"config_files\": [],\n        \"dependencies\": []\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false\n      },\n      \"api_endpoints\": {\n        \"chat_completions\": \"https://api.openai.com/v1/chat/completions\",\n        \"responses\": \"https://api.openai.com/v1/responses\",\n        \"files\": \"https://api.openai.com/v1/files\"\n      },\n      \"vision_api_format\": {\n        \"image_url\": {\n          \"type\": \"image_url\",\n          \"image_url\": {\n            \"url\": \"data:image/jpeg;base64,{base64_string}\",\n            \"detail\": \"high|low|auto\"\n          }\n        },\n        \"supported_formats\": [\"PNG\", \"JPEG\", \"WEBP\", \"GIF (non-animated)\"],\n        \"max_payload_size\": \"50 MB\",\n        \"max_images_per_request\": 500\n      },\n      \"gotchas\": [\n        \"Vision API images should be clear, no watermarks\",\n        \"Low detail: 85 token budget, 512x512 resolution\",\n        \"High detail: Higher token cost for fine-grained analysis\",\n        \"May struggle with non-Latin alphabets, small text, rotated content\",\n        \"Not suitable for specialized medical image interpretation\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /websites/platform_openai\",\n        \"Context7 MCP: /openai/openai-node\",\n        \"https://platform.openai.com/docs/guides/vision\"\n      ]\n    },\n    {\n      \"name\": \"Anthropic API (Claude)\",\n      \"type\": \"service\",\n      \"verified_package\": {\n        \"name\": \"@anthropic-ai/sdk\",\n        \"install_command\": \"npm install @anthropic-ai/sdk\",\n        \"version\": \"latest\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import Anthropic from '@anthropic-ai/sdk'\"\n        ],\n        \"initialization\": \"const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })\",\n        \"key_functions\": [\n          \"anthropic.messages.create({ model, max_tokens, messages })\"\n        ],\n        \"verified_against\": \"Context7 MCP: /anthropics/anthropic-sdk-typescript\"\n      },\n      \"configuration\": {\n        \"env_vars\": [\"ANTHROPIC_API_KEY\"],\n        \"config_files\": [],\n        \"dependencies\": [\"zod (optional, for tool schemas)\"]\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false\n      },\n      \"api_endpoints\": {\n        \"messages\": \"https://api.anthropic.com/v1/messages\"\n      },\n      \"vision_api_format\": {\n        \"image\": {\n          \"type\": \"image\",\n          \"source\": {\n            \"type\": \"base64\",\n            \"media_type\": \"image/jpeg\",\n            \"data\": \"{base64_string}\"\n          }\n        }\n      },\n      \"headers\": {\n        \"x-api-key\": \"API key header\",\n        \"anthropic-version\": \"2023-06-01\"\n      },\n      \"gotchas\": [\n        \"Uses x-api-key header instead of Authorization Bearer\",\n        \"Image source uses 'type: base64' and 'media_type' fields\",\n        \"anthropic-version header is required\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /anthropics/anthropic-sdk-typescript\",\n        \"https://docs.anthropic.com/en/api/messages\"\n      ]\n    },\n    {\n      \"name\": \"Google Gemini API\",\n      \"type\": \"service\",\n      \"verified_package\": {\n        \"name\": \"@google/generative-ai\",\n        \"install_command\": \"npm install @google/generative-ai\",\n        \"version\": \"latest\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import { GoogleGenAI } from '@google/generative-ai'\"\n        ],\n        \"initialization\": \"const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY })\",\n        \"key_functions\": [\n          \"ai.models.generateContent({ model, contents, config })\"\n        ],\n        \"verified_against\": \"Context7 MCP: /websites/ai_google_dev_gemini-api\"\n      },\n      \"configuration\": {\n        \"env_vars\": [\"GEMINI_API_KEY\", \"GOOGLE_API_KEY\"],\n        \"config_files\": [],\n        \"dependencies\": []\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false\n      },\n      \"api_endpoints\": {\n        \"generate_content\": \"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent\"\n      },\n      \"vision_api_format\": {\n        \"inline_data\": {\n          \"mime_type\": \"image/jpeg\",\n          \"data\": \"{base64_string}\"\n        },\n        \"openai_compatible\": {\n          \"type\": \"image_url\",\n          \"image_url\": {\n            \"url\": \"data:image/jpeg;base64,{base64_string}\"\n          }\n        }\n      },\n      \"models\": {\n        \"current\": \"gemini-2.0-flash\",\n        \"vision\": \"gemini-2.5-flash-image\"\n      },\n      \"gotchas\": [\n        \"Supports OpenAI-compatible endpoint at /v1beta/openai/chat/completions\",\n        \"Native API uses 'inline_data' with 'mime_type' and 'data' fields\",\n        \"Can use same request format as OpenAI with OpenAI SDK pointing to Google base URL\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /websites/ai_google_dev_gemini-api\",\n        \"https://ai.google.dev/gemini-api/docs\"\n      ]\n    },\n    {\n      \"name\": \"OpenRouter API\",\n      \"type\": \"service\",\n      \"verified_package\": {\n        \"name\": null,\n        \"install_command\": \"Uses OpenAI SDK with custom base URL\",\n        \"version\": null,\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import OpenAI from 'openai'\"\n        ],\n        \"initialization\": \"const openai = new OpenAI({ apiKey: OPENROUTER_KEY, baseURL: 'https://openrouter.ai/api/v1' })\",\n        \"key_functions\": [\n          \"openai.chat.completions.create({ model: 'google/gemini-3-pro', messages })\"\n        ],\n        \"verified_against\": \"Code inspection in pips-solver/src/services/extraction/apiClient.ts\"\n      },\n      \"configuration\": {\n        \"env_vars\": [\"OPENROUTER_API_KEY\"],\n        \"config_files\": [],\n        \"dependencies\": [\"openai (npm package for client)\"]\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false\n      },\n      \"api_endpoints\": {\n        \"chat_completions\": \"https://openrouter.ai/api/v1/chat/completions\"\n      },\n      \"headers\": {\n        \"Authorization\": \"Bearer {API_KEY}\",\n        \"HTTP-Referer\": \"Your app URL\",\n        \"X-Title\": \"Your app name\"\n      },\n      \"model_format\": {\n        \"gemini\": \"google/gemini-3-pro-preview\",\n        \"gpt\": \"openai/gpt-5.2\",\n        \"claude\": \"anthropic/claude-opus-4.5\"\n      },\n      \"gotchas\": [\n        \"Uses OpenAI-compatible API format\",\n        \"Single API key provides access to multiple providers\",\n        \"Model names use provider/model format\",\n        \"Requires HTTP-Referer and X-Title headers for some features\"\n      ],\n      \"research_sources\": [\n        \"Code inspection: pips-solver/src/services/extraction/apiClient.ts\",\n        \"Code inspection: pips-solver/src/services/extraction/config.ts\"\n      ]\n    },\n    {\n      \"name\": \"OpenCV (Python)\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"opencv-python\",\n        \"install_command\": \"pip install opencv-python>=4.8.0\",\n        \"version\": \">=4.8.0\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import cv2\",\n          \"import numpy as np\"\n        ],\n        \"initialization\": \"img = cv2.imread('image.png')\",\n        \"key_functions\": [\n          \"cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\",\n          \"cv2.GaussianBlur(gray, (5,5), 0)\",\n          \"cv2.Canny(blur, threshold1, threshold2)\",\n          \"cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\",\n          \"cv2.boundingRect(contour)\",\n          \"cv2.rectangle(img, (x,y), (x+w,y+h), color, thickness)\"\n        ],\n        \"verified_against\": \"Context7 MCP: /websites/opencv_5_x, /opencv/opencv-python\"\n      },\n      \"configuration\": {\n        \"env_vars\": [],\n        \"config_files\": [],\n        \"dependencies\": [\"numpy>=1.24.0\"]\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false\n      },\n      \"gotchas\": [\n        \"opencv-python is the pre-built CPU-only package\",\n        \"opencv-python-headless is for server environments without GUI\",\n        \"Canny edge detection requires grayscale input\",\n        \"findContours modifies the source image in some versions\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /websites/opencv_5_x\",\n        \"Context7 MCP: /opencv/opencv-python\",\n        \"Code inspection: extract_board_cells.py\"\n      ]\n    },\n    {\n      \"name\": \"FastAPI\",\n      \"type\": \"framework\",\n      \"verified_package\": {\n        \"name\": \"fastapi\",\n        \"install_command\": \"pip install fastapi>=0.104.0 uvicorn>=0.24.0\",\n        \"version\": \">=0.104.0\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"from fastapi import FastAPI, File, UploadFile, Form\",\n          \"from typing import Annotated\"\n        ],\n        \"initialization\": \"app = FastAPI()\",\n        \"key_functions\": [\n          \"@app.post('/upload/')\",\n          \"async def upload_file(file: Annotated[UploadFile, File()])\",\n          \"content = await file.read()\",\n          \"uvicorn.run(app, host='0.0.0.0', port=8000)\"\n        ],\n        \"verified_against\": \"Context7 MCP: /fastapi/fastapi\"\n      },\n      \"configuration\": {\n        \"env_vars\": [],\n        \"config_files\": [],\n        \"dependencies\": [\n          \"uvicorn>=0.24.0\",\n          \"python-multipart>=0.0.6\",\n          \"pydantic>=2.0.0\"\n        ]\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false,\n        \"ports\": [8000]\n      },\n      \"gotchas\": [\n        \"python-multipart is required for form data and file uploads\",\n        \"Use Annotated[UploadFile, File()] for file parameters\",\n        \"File.read() returns bytes, use await for async\",\n        \"Multiple files: Annotated[list[UploadFile], File()]\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /fastapi/fastapi\",\n        \"Code inspection: cv-service/requirements.txt\"\n      ]\n    },\n    {\n      \"name\": \"React Navigation\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"@react-navigation/native\",\n        \"install_command\": \"npm install @react-navigation/native @react-navigation/stack\",\n        \"version\": \"^7.1.25\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import { NavigationContainer } from '@react-navigation/native'\",\n          \"import { createStackNavigator } from '@react-navigation/stack'\"\n        ],\n        \"initialization\": \"const Stack = createStackNavigator()\",\n        \"key_functions\": [\n          \"<NavigationContainer>\",\n          \"<Stack.Navigator>\",\n          \"<Stack.Screen name='Home' component={HomeScreen} />\",\n          \"navigation.navigate('ScreenName')\"\n        ],\n        \"verified_against\": \"Package.json inspection\"\n      },\n      \"configuration\": {\n        \"env_vars\": [],\n        \"config_files\": [],\n        \"dependencies\": [\n          \"react-native-screens\",\n          \"react-native-safe-area-context\",\n          \"react-native-gesture-handler\"\n        ]\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false\n      },\n      \"gotchas\": [\n        \"Requires react-native-screens and react-native-safe-area-context\",\n        \"Gesture handler must be imported at app entry point\"\n      ],\n      \"research_sources\": [\n        \"Package.json inspection: pips-solver/package.json\"\n      ]\n    },\n    {\n      \"name\": \"AsyncStorage\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"@react-native-async-storage/async-storage\",\n        \"install_command\": \"npx expo install @react-native-async-storage/async-storage\",\n        \"version\": \"^2.2.0\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import AsyncStorage from '@react-native-async-storage/async-storage'\"\n        ],\n        \"initialization\": \"No initialization needed\",\n        \"key_functions\": [\n          \"await AsyncStorage.setItem('key', JSON.stringify(value))\",\n          \"await AsyncStorage.getItem('key')\",\n          \"await AsyncStorage.removeItem('key')\",\n          \"await AsyncStorage.clear()\"\n        ],\n        \"verified_against\": \"Package.json inspection\"\n      },\n      \"configuration\": {\n        \"env_vars\": [],\n        \"config_files\": [],\n        \"dependencies\": []\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false\n      },\n      \"gotchas\": [\n        \"Only stores strings - must JSON.stringify objects\",\n        \"Has size limitations - consider expo-file-system for large data\"\n      ],\n      \"research_sources\": [\n        \"Package.json inspection: pips-solver/package.json\"\n      ]\n    },\n    {\n      \"name\": \"PyYAML\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"PyYAML\",\n        \"install_command\": \"pip install PyYAML\",\n        \"version\": \"latest\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import yaml\"\n        ],\n        \"initialization\": \"No initialization needed\",\n        \"key_functions\": [\n          \"yaml.safe_load(file)\",\n          \"yaml.dump(data)\"\n        ],\n        \"verified_against\": \"Code inspection: solve_pips.py\"\n      },\n      \"configuration\": {\n        \"env_vars\": [],\n        \"config_files\": [],\n        \"dependencies\": []\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false\n      },\n      \"gotchas\": [\n        \"Always use safe_load() instead of load() for security\",\n        \"YAML preserves multi-line strings with | or > syntax\"\n      ],\n      \"research_sources\": [\n        \"Code inspection: solve_pips.py\"\n      ]\n    },\n    {\n      \"name\": \"YAML (JavaScript)\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"yaml\",\n        \"install_command\": \"npm install yaml\",\n        \"version\": \"^2.8.2\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import YAML from 'yaml'\"\n        ],\n        \"initialization\": \"No initialization needed\",\n        \"key_functions\": [\n          \"YAML.parse(yamlString)\",\n          \"YAML.stringify(object)\"\n        ],\n        \"verified_against\": \"Package.json inspection\"\n      },\n      \"configuration\": {\n        \"env_vars\": [],\n        \"config_files\": [],\n        \"dependencies\": []\n      },\n      \"infrastructure\": {\n        \"requires_docker\": false\n      },\n      \"gotchas\": [],\n      \"research_sources\": [\n        \"Package.json inspection: pips-solver/package.json\"\n      ]\n    }\n  ],\n  \"unverified_claims\": [\n    {\n      \"claim\": \"Model IDs: google/gemini-3-pro-preview, openai/gpt-5.2, anthropic/claude-opus-4.5\",\n      \"reason\": \"These are future model versions referenced in code (Dec 2025 dates). Current models as of Dec 2024 are gemini-2.0-flash, gpt-4, claude-3.5-sonnet. The code appears to be forward-looking.\",\n      \"risk_level\": \"medium\"\n    },\n    {\n      \"claim\": \"OpenRouter full vision API support for all three providers\",\n      \"reason\": \"Could not fetch OpenRouter documentation directly to verify vision support. Code shows OpenRouter is used but API compatibility should be tested.\",\n      \"risk_level\": \"low\"\n    }\n  ],\n  \"project_context\": {\n    \"description\": \"NYT Pips puzzle solver with multi-stage AI extraction pipeline\",\n    \"components\": {\n      \"python_backend\": {\n        \"purpose\": \"Computer vision grid extraction and CSP puzzle solving\",\n        \"key_files\": [\n          \"solve_pips.py\",\n          \"extract_board_cells_gridlines.py\",\n          \"cv-service/\"\n        ]\n      },\n      \"react_native_app\": {\n        \"purpose\": \"Mobile app for puzzle solving with AI extraction\",\n        \"key_directory\": \"pips-solver/\",\n        \"extraction_service\": \"pips-solver/src/services/extraction/\"\n      }\n    },\n    \"ai_extraction_pipeline\": {\n      \"stages\": 5,\n      \"stage_names\": [\n        \"Grid Geometry\",\n        \"Cell Detection\",\n        \"Region Mapping\",\n        \"Constraint Extraction\",\n        \"Domino Extraction\"\n      ],\n      \"ensemble_approach\": \"3-model consensus (Gemini, GPT, Claude)\",\n      \"consensus_algorithm\": \"Confidence-weighted voting with majority fallback\"\n    }\n  },\n  \"recommendations\": [\n    \"Verify actual model availability on OpenRouter before deployment - model IDs in code reference future versions\",\n    \"Consider adding retry logic with exponential backoff for all AI API calls (already present in apiClient.ts)\",\n    \"Test extraction pipeline with multiple puzzle screenshots to verify accuracy improvements\",\n    \"Consider using opencv-python-headless for cv-service if running in containerized environment\",\n    \"Implement response caching for repeated extractions of the same image\",\n    \"Add logging/telemetry to measure extraction stage accuracy individually\",\n    \"Consider fallback to legacy extraction (aiExtraction.ts, ensembleExtraction.ts) if new pipeline fails\"\n  ],\n  \"existing_gotchas_in_codebase\": [\n    {\n      \"file\": \"CLAUDE.md\",\n      \"issue\": \"LLM JSON Response Handling - Vision LLMs often return multiline strings incorrectly formatted\",\n      \"solution\": \"Use parseJSONWithFallback() from jsonParsingUtils.ts\"\n    },\n    {\n      \"file\": \"CLAUDE.md\",\n      \"issue\": \"Prompt Engineering - DRY for prompts, magic numbers should be in config.ts\",\n      \"solution\": \"Use NYT_VALIDATION constants and shared prompt templates\"\n    },\n    {\n      \"file\": \"src/services/extraction/config.ts\",\n      \"issue\": \"Confidence threshold: 0.70 for retry trigger, 0.10 gap for high confidence\",\n      \"solution\": \"These are tunable parameters in DEFAULT_CONFIG\"\n    }\n  ],\n  \"context7_libraries_used\": [\n    \"/expo/expo\",\n    \"/software-mansion/react-native-svg\",\n    \"/colinhacks/zod\",\n    \"/websites/platform_openai\",\n    \"/anthropics/anthropic-sdk-typescript\",\n    \"/websites/ai_google_dev_gemini-api\",\n    \"/fastapi/fastapi\",\n    \"/websites/opencv_5_x\",\n    \"/opencv/opencv-python\"\n  ],\n  \"created_at\": \"2024-12-22T00:00:00Z\"\n}\n",
        "last_modified": "2025-12-22T03:30:38.613340"
      },
      "task_intent": {
        "title": "005-add-image-stats-diagnostic-endpoint",
        "description": "Create a _calculate_image_stats function and expose it as a standalone API endpoint that returns brightness, contrast, dynamic range, color balance, and saturation metrics without requiring preprocessing. This helps users diagnose image quality issues before extraction.",
        "from_plan": true
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2025-12-22T03:09:17.916628",
  "last_updated": "2025-12-22T03:09:18.031159"
}