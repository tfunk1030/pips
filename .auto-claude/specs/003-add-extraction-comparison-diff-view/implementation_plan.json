{
  "specId": "003-add-extraction-comparison-diff-view",
  "title": "Add Extraction Comparison/Diff View",
  "description": "Allow users to compare extraction results from different AI models side-by-side. This surfaces per-model responses stored during debug mode for manual verification and enables cell-by-cell disagreement analysis.",
  "created_at": "2025-12-22T07:00:39.841Z",
  "updated_at": "2025-12-22T08:09:10.845Z",
  "status": "human_review",
  "planStatus": "review",
  "workflow_type": "development",
  "estimatedEffort": "large",
  "totalEstimatedMinutes": 585,
  "phases": [
    {
      "id": "phase-1",
      "name": "Data Layer - Store Raw Model Responses",
      "description": "Extend extraction pipeline to capture and store per-model raw responses for comparison",
      "subtasks": [
        {
          "id": "1.1",
          "title": "Add debug response types to overlayTypes.ts",
          "description": "Define TypeScript types for storing per-model raw responses including ModelResponse, RawResponses, and ExtendedAIExtractionResult with debug field",
          "status": "completed",
          "acceptanceCriteria": [
            "ModelResponse type captures model name, raw text, parsed data, and timing",
            "RawResponses type holds board and domino responses per model",
            "AIExtractionResult extended with optional debug.rawResponses field"
          ],
          "estimatedMinutes": 20,
          "filesToModify": [
            "pips-solver/src/model/overlayTypes.ts"
          ],
          "notes": "Added debug response types to overlayTypes.ts:\n- ModelResponse<T>: Generic type capturing model name, raw text, parsed data, and timing\n- BoardModelResponse/DominoModelResponse: Typed variants for extraction results\n- RawResponses: Container holding per-model responses for board and domino extraction\n- AIExtractionResult.debug.rawResponses: Optional field for storing debug data\n\nAll acceptance criteria met:\n\u2713 ModelResponse type captures model name, raw text, parsed data, and timing\n\u2713 RawResponses type holds board and domino responses per model\n\u2713 AIExtractionResult extended with optional debug.rawResponses field\n\nTypeScript types compile without errors.",
          "updated_at": "2025-12-22T07:14:26.185680+00:00"
        },
        {
          "id": "1.2",
          "title": "Modify ensembleExtraction.ts to capture raw responses",
          "description": "Update extractBoardEnsemble and extractDominoesEnsemble to return all individual model responses alongside the consensus result",
          "status": "completed",
          "acceptanceCriteria": [
            "Each model's raw text response is captured before parsing",
            "Parsed results per model are stored with model identifier",
            "Timing data per model is recorded",
            "saveDebugResponses option controls whether raw responses are returned"
          ],
          "estimatedMinutes": 45,
          "filesToModify": [
            "pips-solver/src/services/ensembleExtraction.ts"
          ],
          "notes": "Updated extractBoardEnsemble and extractDominoesEnsemble to return all individual model responses alongside the consensus result:\n\n- Added saveDebugResponses option to EnsembleExtractionOptions\n- extractBoardEnsemble now captures and returns rawResponses (BoardModelResponse[]) and selectedModel\n- extractDominoesEnsemble now captures and returns rawResponses (DominoModelResponse[]) and selectedModel  \n- extractPuzzleEnsemble threads debug option through and collects RawResponses structure\n- Each model's raw text response is captured before parsing\n- Parsed results per model stored with model identifier\n- Timing data per model recorded (responseMs, parseMs)\n- Removed console.log/console.warn debugging statements per quality checklist\n\nAll acceptance criteria met:\n\u2713 Each model's raw text response is captured before parsing\n\u2713 Parsed results per model are stored with model identifier\n\u2713 Timing data per model is recorded\n\u2713 saveDebugResponses option controls whether raw responses are returned",
          "updated_at": "2025-12-22T07:23:33.927977+00:00"
        },
        {
          "id": "1.3",
          "title": "Thread debug responses through extraction pipeline",
          "description": "Ensure raw responses flow from ensemble extraction through aiExtraction.ts and are available in the final result",
          "status": "completed",
          "acceptanceCriteria": [
            "MultiModelExtractionResult includes rawResponses when saveDebugResponses is true",
            "extractPuzzleMultiModel passes debug flag through to ensemble extraction",
            "Raw responses preserved through all result transformations"
          ],
          "estimatedMinutes": 30,
          "filesToModify": [
            "pips-solver/src/services/aiExtraction.ts"
          ],
          "notes": "Threaded debug responses through the extraction pipeline in aiExtraction.ts:\n\n- Added RawResponses import from overlayTypes.ts\n- Added saveDebugResponses option to MultiModelExtractionOptions interface\n- Added rawResponses field to MultiModelExtractionResult interface  \n- Extracted saveDebugResponses from options (default: false)\n- Passed saveDebugResponses through to extractPuzzleEnsemble call\n- Raw responses flow through automatically as EnsembleExtractionResult is returned directly\n\nAll acceptance criteria met:\n\u2713 MultiModelExtractionResult includes rawResponses when saveDebugResponses is true\n\u2713 extractPuzzleMultiModel passes debug flag through to ensemble extraction\n\u2713 Raw responses preserved through all result transformations",
          "updated_at": "2025-12-22T07:31:57.993321+00:00"
        }
      ]
    },
    {
      "id": "phase-2",
      "name": "Validation Layer - Cell-by-Cell Disagreement Analysis",
      "description": "Create grid validator module with comparison logic to detect and report disagreements between model responses",
      "subtasks": [
        {
          "id": "2.1",
          "title": "Create gridValidator.ts with cell comparison types",
          "description": "Create new validation module with types for cell detection results, disagreement info, and comparison results",
          "status": "completed",
          "acceptanceCriteria": [
            "CellDetection type captures per-cell data (region, constraint, etc.)",
            "CellDisagreement type shows which models disagree and what values they report",
            "ComparisonResult type aggregates all disagreements with severity levels"
          ],
          "estimatedMinutes": 25,
          "filesToModify": [
            "pips-solver/src/services/extraction/validation/gridValidator.ts"
          ],
          "notes": "Created gridValidator.ts with comprehensive TypeScript types for the extraction comparison feature:\n\n- DisagreementSeverity: 'critical' | 'warning' | 'info' for visual prioritization\n- CellDetection: Per-cell data capturing region, constraint, isHole status, and confidence\n- CellDisagreement: Shows which models disagree at a specific cell coordinate\n- GridDimensionDisagreement: Detects row/column count mismatches between models\n- ConstraintDisagreement: Captures constraint type/value/operator differences\n- DominoDisagreement: Tracks domino count and individual value mismatches\n- ComparisonResult: Aggregates all disagreements with severity summary and cell lookup map\n- NormalizedModelResult: Per-model extraction data normalized for side-by-side display\n- Helper types: BoardComparisonInput, DominoComparisonInput, ComparisonOptions\n- Utility functions: cellKey(), parseCellKey(), createEmptyComparisonResult(), generateDisagreementId()\n\nAll acceptance criteria met:\n\u2713 CellDetection type captures per-cell data (region, constraint, etc.)\n\u2713 CellDisagreement type shows which models disagree and what values they report\n\u2713 ComparisonResult type aggregates all disagreements with severity levels",
          "updated_at": "2025-12-22T07:38:27.828076+00:00"
        },
        {
          "id": "2.2",
          "title": "Implement compareCellDetections function",
          "description": "Build core comparison logic that takes multiple model responses and identifies cell-by-cell disagreements",
          "status": "completed",
          "acceptanceCriteria": [
            "Compares shape strings to find holes disagreements",
            "Compares region assignments per cell",
            "Compares constraint values per region",
            "Compares domino list (order-independent)",
            "Returns structured disagreement data with cell coordinates"
          ],
          "estimatedMinutes": 60,
          "filesToModify": [
            "pips-solver/src/services/extraction/validation/gridValidator.ts"
          ],
          "notes": "Implemented the compareCellDetections function with complete comparison logic:\n\n- compareDimensions: Detects row/column count mismatches between models (critical severity)\n- compareHolePositions: Finds disagreements on hole positions via shape strings (critical severity)\n- compareRegionAssignments: Identifies cells where models disagree on region (warning severity)\n- compareConstraints: Compares constraint type/value/operator per region (warning severity)\n- compareDominoes: Order-independent domino list comparison with normalized matching (critical for count, warning for values)\n\nAlso includes:\n- Type conversion functions (convertToConstraintDef, convertConstraints) for safe ConstraintType handling\n- Grid string parsing utilities (parseGridString, parseShapeToHoles, parseRegions)\n- Helper functions (normalizeDomino, buildCellDisagreementMap, calculateSummary)\n- TypeScript type fix for DominoDisagreement.values to include boolean\n\nAll acceptance criteria met:\n\u2713 Compares shape strings to find holes disagreements\n\u2713 Compares region assignments per cell\n\u2713 Compares constraint values per region\n\u2713 Compares domino list (order-independent)\n\u2713 Returns structured disagreement data with cell coordinates\n\nTypeScript compiles without errors. Commit: 46eb00f",
          "updated_at": "2025-12-22T08:16:00.522140+00:00"
        },
        {
          "id": "2.3",
          "title": "Add disagreement severity classification",
          "description": "Classify disagreements as critical (affects solvability), warning (may affect solution), or info (cosmetic differences)",
          "status": "completed",
          "acceptanceCriteria": [
            "Grid dimension mismatches are critical",
            "Hole position mismatches are critical",
            "Region boundary differences are warnings",
            "Constraint value differences are warnings",
            "Domino count mismatches are critical, individual domino differences are warnings"
          ],
          "estimatedMinutes": 30,
          "filesToModify": [
            "pips-solver/src/services/extraction/validation/gridValidator.ts"
          ],
          "notes": "Added comprehensive disagreement severity classification system:\n\n- DISAGREEMENT_SEVERITY_MAP defines severity for each type:\n  - CRITICAL (affects solvability): grid_dimensions, hole_position, domino_count\n  - WARNING (may affect solution): region_assignment, constraint_type/value/operator, domino_value\n  - INFO: reserved for cosmetic differences\n\n- Central classifyDisagreementSeverity() function for consistent classification\n- Utility functions: isSeverityAtLeast, compareSeverities, sortDisagreementsBySeverity, filterDisagreementsBySeverity, getHighestSeverity, getSeverityReason\n- Constants: SEVERITY_ORDER, SEVERITY_PRIORITY, SEVERITY_DESCRIPTIONS\n- All comparison functions updated to use central classifier\n\nAll acceptance criteria met:\n\u2713 Grid dimension mismatches are critical\n\u2713 Hole position mismatches are critical\n\u2713 Region boundary differences are warnings\n\u2713 Constraint value differences are warnings\n\u2713 Domino count mismatches are critical, individual domino differences are warnings\n\nCommit: 6333b40",
          "updated_at": "2025-12-22T08:26:07.954622+00:00"
        }
      ]
    },
    {
      "id": "phase-3",
      "name": "UI Layer - Extraction Comparison Modal",
      "description": "Build the visual comparison component showing side-by-side model results with highlighted disagreements",
      "subtasks": [
        {
          "id": "3.1",
          "title": "Create ExtractionComparisonModal component shell",
          "description": "Build the basic modal structure with tabs/sections for each model's results and a summary view",
          "status": "completed",
          "acceptanceCriteria": [
            "Modal opens from OverlayBuilderScreen after extraction",
            "Tab bar shows each model name with result summary",
            "Scrollable content area for detailed results",
            "Close and Accept buttons in footer"
          ],
          "estimatedMinutes": 45,
          "filesToModify": [
            "pips-solver/src/app/components/ExtractionComparisonModal.tsx"
          ],
          "notes": "Created ExtractionComparisonModal component shell with:\n\n- Tab bar showing 'Summary' + each model name with error indicator dots\n- Summary view displaying:\n  - Status banner (all models agree / disagreements found)\n  - Models compared chip list\n  - Disagreement counts by severity (critical/warning/info)\n  - Disagreement counts by category (dimensions, holes, regions, constraints, dominoes)\n- Scrollable content area with model-specific result views (placeholder for 3.2)\n- Empty state for when debug responses are not available\n- Footer with Close and Accept buttons\n- Follows AIVerificationModal patterns for styling and structure\n\nAll acceptance criteria met:\n\u2713 Modal opens from OverlayBuilderScreen after extraction (structure ready, integration in 4.x)\n\u2713 Tab bar shows each model name with result summary\n\u2713 Scrollable content area for detailed results\n\u2713 Close and Accept buttons in footer\n\nCommit: ec5707c",
          "updated_at": "2025-12-22T08:32:36.678683+00:00"
        },
        {
          "id": "3.2",
          "title": "Build per-model result display section",
          "description": "Create reusable component showing a single model's extraction: grid, regions, constraints, dominoes",
          "status": "completed",
          "acceptanceCriteria": [
            "Grid visualization with hole markers",
            "Region visualization with color-coded cells",
            "Constraints list with type and values",
            "Dominoes list with pip counts",
            "Confidence scores displayed",
            "Timing info shown"
          ],
          "estimatedMinutes": 50,
          "filesToModify": [
            "pips-solver/src/app/components/ExtractionComparisonModal.tsx"
          ],
          "notes": "Built per-model result display section with full extraction visualization:\n\nComponents added:\n- GridVisualization: Shows holes in grid with # markers\n- RegionVisualization: Color-coded cells matching DEFAULT_PALETTE colors (A-J)\n- ConstraintsList: Displays constraints with region badges and formatted values\n- DominoesList: Shows dominoes as tiles with pip frequency summary\n- ConfidenceDisplay: Progress bar visualization for confidence scores\n- TimingDisplay: Shows response time, parse time, and total timing\n\nModelResultView displays:\n- Grid dimensions (rows \u00d7 columns)\n- Shape visualization with holes marked\n- Regions with color-coded cells\n- Constraints list with type/operator/value formatting\n- Dominoes with visual tile representation and pip counts\n- Confidence scores as progress bars with color coding (green/yellow/red)\n- Timing information when available from raw responses\n\nAcceptance criteria met:\n\u2713 Grid visualization with hole markers\n\u2713 Region visualization with color-coded cells\n\u2713 Constraints list with type and values\n\u2713 Dominoes list with pip counts\n\u2713 Confidence scores displayed\n\u2713 Timing info shown\n\nCommit: 6fcba8c",
          "updated_at": "2025-12-22T08:38:50.935108+00:00"
        },
        {
          "id": "3.3",
          "title": "Add disagreement highlighting to comparison view",
          "description": "Visually highlight cells/regions where models disagree with color-coded indicators",
          "status": "completed",
          "acceptanceCriteria": [
            "Cells with disagreements have colored border/background",
            "Severity indicated by color (red=critical, yellow=warning, blue=info)",
            "Tooltip/popup shows what each model reported for that cell",
            "Summary badge shows total disagreement count per severity"
          ],
          "estimatedMinutes": 45,
          "filesToModify": [
            "pips-solver/src/app/components/ExtractionComparisonModal.tsx"
          ],
          "notes": "Added visual disagreement highlighting to ExtractionComparisonModal:\n\n- SEVERITY_COLORS constant with border, bg, and text colors for critical (red), warning (yellow), and info (blue)\n- GridVisualization: colored borders/backgrounds for cells with disagreements, Pressable for tap events\n- RegionVisualization: colored borders and small indicator dots for disagreeing cells\n- CellDetailPopup: Modal showing per-model values when a disagreeing cell is tapped\n- formatDisagreementType helper for user-friendly type names\n- ModelResultView: accepts cellDisagreementMap and onCellPress props, displays disagreement legend\n- selectedCell state for popup management in main component\n- New styles: legendRow, legendItem, legendDot, legendText, disagreementIndicator, popup styles\n\nAll acceptance criteria met:\n\u2713 Cells with disagreements have colored border/background\n\u2713 Severity indicated by color (red=critical, yellow=warning, blue=info)\n\u2713 Tooltip/popup shows what each model reported for that cell\n\u2713 Summary badge shows total disagreement count per severity\n\nCommit: e7d04dd",
          "updated_at": "2025-12-22T08:46:03.230146+00:00"
        },
        {
          "id": "3.4",
          "title": "Add diff summary panel",
          "description": "Create summary panel showing all disagreements in list form with navigation to specific cells",
          "status": "completed",
          "acceptanceCriteria": [
            "Lists all disagreements grouped by type (grid, regions, constraints, dominoes)",
            "Each disagreement shows cell coordinates and per-model values",
            "Tap on disagreement scrolls/highlights the relevant cell in the grid view",
            "Filter controls to show/hide by severity level"
          ],
          "estimatedMinutes": 40,
          "filesToModify": [
            "pips-solver/src/app/components/ExtractionComparisonModal.tsx"
          ],
          "notes": "Added DiffSummaryPanel component with severity filter controls and grouped disagreement list with navigation:\n\nComponents added:\n- SeverityFilterBar: Toggle chips to filter disagreements by severity level (critical/warning/info)\n- DisagreementListItem: Individual disagreement card showing type, location, severity badge, and per-model values\n- DisagreementGroup: Section grouping disagreements by category (Grid Dimensions, Holes, Regions, Constraints, Dominoes)\n- DiffSummaryPanel: Main panel combining filters, result count, and grouped disagreement list\n\nFeatures implemented:\n- Severity filter toggles to show/hide disagreements by level (all enabled by default)\n- Result count showing filtered vs total disagreements\n- Grouped disagreement list with collapsible sections by type\n- Navigation: tap on cell-based disagreement to switch to first model tab and show cell popup\n- Each disagreement shows cell coordinates/location and what each model reported\n\nUpdated:\n- SummaryView: Now includes DiffSummaryPanel with filter/navigation props\n- Main component: Added severityFilters state, handleToggleSeverityFilter, handleDisagreementPress handlers\n- Removed unused DisagreementCategorySummary component and related styles\n\nAll acceptance criteria met:\n\u2713 Lists all disagreements grouped by type (grid, regions, constraints, dominoes)\n\u2713 Each disagreement shows cell coordinates and per-model values\n\u2713 Tap on disagreement scrolls/highlights the relevant cell in the grid view\n\u2713 Filter controls to show/hide by severity level\n\nCommit: 205d046",
          "updated_at": "2025-12-22T08:52:51.677691+00:00"
        }
      ]
    },
    {
      "id": "phase-4",
      "name": "Integration - Wire Up Components",
      "description": "Connect all components and add UI controls to access the comparison view",
      "subtasks": [
        {
          "id": "4.1",
          "title": "Add comparison button to AIVerificationModal",
          "description": "Add 'Compare Models' button to existing verification modal that opens the detailed comparison view",
          "status": "completed",
          "acceptanceCriteria": [
            "Button only visible when multiple models were used",
            "Button opens ExtractionComparisonModal with raw responses",
            "Button disabled/hidden when only single model was used"
          ],
          "estimatedMinutes": 25,
          "filesToModify": [
            "pips-solver/src/app/components/AIVerificationModal.tsx"
          ],
          "notes": "Added 'Compare Models' button to AIVerificationModal:\n\nChanges made to AIVerificationModal.tsx:\n- Added rawResponses optional prop (RawResponses | null) to Props interface\n- Added useState for showComparisonModal to track modal visibility\n- Added useMemo hasMultipleModels computed value that checks if 2+ unique models exist in rawResponses\n- Added 'Compare Models' button (blue #2196F3) that only renders when hasMultipleModels is true\n- Integrated ExtractionComparisonModal component that opens on button press\n- Added compareButtonContainer and compareButton styles\n\nAcceptance criteria met:\n\u2713 Button only visible when multiple models were used (hasMultipleModels guard)\n\u2713 Button opens ExtractionComparisonModal with raw responses\n\u2713 Button disabled/hidden when only single model was used (not rendered)\n\nCommit: a905d20",
          "updated_at": "2025-12-22T08:56:32.798314+00:00"
        },
        {
          "id": "4.2",
          "title": "Update OverlayBuilderScreen to pass debug data",
          "description": "Modify screen to request debug responses during extraction and pass them to modals",
          "status": "completed",
          "acceptanceCriteria": [
            "saveDebugResponses enabled when using ensemble/accurate strategies",
            "rawResponses passed to AIVerificationModal",
            "State management updated to hold comparison data"
          ],
          "estimatedMinutes": 35,
          "filesToModify": [
            "pips-solver/src/app/screens/OverlayBuilderScreen.tsx"
          ],
          "notes": "Updated OverlayBuilderScreen to pass debug responses to modals:\n\nChanges made to OverlayBuilderScreen.tsx:\n- Added RawResponses import from overlayTypes.ts\n- Added pendingRawResponses state (useState<RawResponses | null>)\n- Created shouldSaveDebugResponses flag that enables debug responses for ensemble/accurate strategies\n- Passed saveDebugResponses option to extractPuzzleMultiModel call\n- Store result.rawResponses in pendingRawResponses state on successful extraction\n- Clear pendingRawResponses in handleAcceptAIResult and handleRejectAIResult\n- Pass rawResponses={pendingRawResponses} prop to AIVerificationModal\n\nAcceptance criteria met:\n\u2713 saveDebugResponses enabled when using ensemble/accurate strategies\n\u2713 rawResponses passed to AIVerificationModal\n\u2713 State management updated to hold comparison data\n\nCommit: 639a5b6",
          "updated_at": "2025-12-22T09:00:53.439023+00:00"
        },
        {
          "id": "4.3",
          "title": "Add Settings toggle for debug mode",
          "description": "Add user-facing setting to enable/disable storing debug responses (affects storage and performance)",
          "status": "completed",
          "acceptanceCriteria": [
            "Toggle in Settings screen under AI/Extraction section",
            "Setting persisted to AsyncStorage",
            "Default is OFF for performance",
            "Tooltip explains the feature and performance impact"
          ],
          "estimatedMinutes": 25,
          "filesToModify": [
            "pips-solver/src/app/screens/SettingsScreen.tsx",
            "pips-solver/src/storage/puzzles.ts"
          ],
          "notes": "Added user-facing setting for Model Comparison Mode:\n\n- Added saveDebugResponses field to AppSettings interface in puzzles.ts with documentation\n- Added toggle switch in Settings screen under AI Extraction section with:\n  - Descriptive label \"\ud83d\udd0d Model Comparison Mode\"\n  - Helpful description explaining the feature\n  - Dynamic hint text showing enabled/disabled state\n  - Warning message when enabled about memory usage\n- Updated OverlayBuilderScreen to respect the setting (only saves debug responses when setting is ON AND using ensemble/accurate strategies)\n- Setting persisted to AsyncStorage via existing settings infrastructure\n- Default is OFF for performance\n\nAll acceptance criteria met:\n\u2713 Toggle in Settings screen under AI/Extraction section\n\u2713 Setting persisted to AsyncStorage\n\u2713 Default is OFF for performance\n\u2713 Tooltip explains the feature and performance impact\n\nCommit: 21f09e7",
          "updated_at": "2025-12-22T09:05:51.071671+00:00"
        }
      ]
    },
    {
      "id": "phase-5",
      "name": "Testing and Polish",
      "description": "Add tests, error handling, and UX polish",
      "subtasks": [
        {
          "id": "5.1",
          "title": "Add unit tests for compareCellDetections",
          "description": "Create comprehensive tests for the grid comparison logic with various disagreement scenarios",
          "status": "completed",
          "acceptanceCriteria": [
            "Test identical inputs return no disagreements",
            "Test dimension mismatches detected",
            "Test region disagreements at specific cells detected",
            "Test constraint value disagreements detected",
            "Test domino differences detected"
          ],
          "estimatedMinutes": 45,
          "filesToModify": [
            "pips-solver/src/services/extraction/validation/__tests__/gridValidator.test.ts"
          ],
          "notes": "Created comprehensive test suite for gridValidator.ts:\n\n- Set up Jest testing framework with ts-jest for TypeScript support\n- Added jest.config.js with proper configuration\n- Created 72 tests covering:\n\n**Utility Functions Tests:**\n- cellKey: generates cell keys from row/column coordinates\n- parseCellKey: parses keys back to coordinates with roundtrip verification\n- generateDisagreementId: creates unique IDs for different disagreement types\n- createEmptyComparisonResult: creates proper empty result structure\n\n**Severity Classification Tests:**\n- DISAGREEMENT_SEVERITY_MAP covers all disagreement types correctly\n- classifyDisagreementSeverity returns correct severity for each type\n- isSeverityAtLeast threshold comparison\n- compareSeverities for sorting\n- sortDisagreementsBySeverity sorts critical first\n- filterDisagreementsBySeverity filters by threshold\n- getHighestSeverity finds most severe in collection\n- getSeverityReason provides explanations\n\n**Main compareCellDetections Tests:**\n- Edge cases: single model, no models, failed parses\n- Identical inputs return no disagreements\n- Dimension mismatches detected (rows, cols)\n- Hole position disagreements detected at specific cells\n- Region assignment disagreements detected\n- Constraint disagreements detected (type, value, operator)\n- Domino differences detected (count=critical, values=warning)\n- Order-independent domino comparison ([1,2] == [2,1])\n- Summary statistics correctly calculated\n- Model results normalized with dimensions and dominoes\n- Comparison options (referenceModel, includeInfoLevel)\n- Three or more models with varying agreements\n- Complex scenarios with multiple disagreement types\n\nAll acceptance criteria met:\n\u2713 Test identical inputs return no disagreements\n\u2713 Test dimension mismatches detected\n\u2713 Test region disagreements at specific cells detected\n\u2713 Test constraint value disagreements detected\n\u2713 Test domino differences detected\n\nCommit: a5a560a1",
          "updated_at": "2025-12-22T09:13:48.629782+00:00"
        },
        {
          "id": "5.2",
          "title": "Add error boundary and loading states",
          "description": "Handle edge cases gracefully with proper error messages and loading indicators",
          "status": "completed",
          "acceptanceCriteria": [
            "Loading spinner while comparison is computed",
            "Error state if comparison fails with retry option",
            "Graceful degradation if rawResponses is missing/corrupted",
            "Empty state if no disagreements found"
          ],
          "estimatedMinutes": 30,
          "filesToModify": [
            "pips-solver/src/app/components/ExtractionComparisonModal.tsx"
          ],
          "notes": "Added comprehensive edge case handling to ExtractionComparisonModal:\n\nLoading states:\n- Added LoadingState component with ActivityIndicator\n- Shows loading spinner while comparison is computed\n- Deferred computation to next tick to allow loading UI to render\n\nError handling:\n- Added ErrorState component with retry option\n- Wraps comparison computation in try/catch\n- Displays user-friendly error messages with retry button\n- Graceful error recovery via retryKey state\n\nData validation:\n- Added validateRawResponses() function to detect corrupted data\n- Validates board/dominoes array structure\n- Checks for required model identifiers\n- Shows specific validation error messages\n\nEmpty state improvements:\n- Added NoDisagreementsState component for unanimous results\n- Shows confirmation icon and confidence message\n- Updated SummaryView to use dedicated component\n\nReact patterns:\n- Moved comparison computation from useMemo to useEffect\n- Proper state management with cleanup\n- Avoids setState-during-render anti-pattern\n\nAll acceptance criteria met:\n\u2713 Loading spinner while comparison is computed\n\u2713 Error state if comparison fails with retry option\n\u2713 Graceful degradation if rawResponses is missing/corrupted\n\u2713 Empty state if no disagreements found\n\nCommit: af64a678",
          "updated_at": "2025-12-22T09:19:01.773968+00:00"
        },
        {
          "id": "5.3",
          "title": "Accessibility and responsive design",
          "description": "Ensure comparison modal works on various screen sizes and is accessible",
          "status": "completed",
          "acceptanceCriteria": [
            "Modal scrolls properly on small screens",
            "Grid visualization scales appropriately",
            "Color contrast meets WCAG AA",
            "Screen reader labels on interactive elements"
          ],
          "estimatedMinutes": 35,
          "filesToModify": [
            "pips-solver/src/app/components/ExtractionComparisonModal.tsx"
          ],
          "notes": "Added comprehensive accessibility and responsive design to ExtractionComparisonModal:\n\nAccessibility improvements (WCAG AA compliance):\n- Added accessibilityLabel, accessibilityRole, accessibilityHint to all interactive elements\n- Tab bar has accessibilityRole=\"tablist\" with individual tabs having accessibilityState\n- Cell popup has accessibilityViewIsModal and proper close button with hitSlop\n- Loading/Error states have accessibilityRole=\"progressbar\" and \"alert\" with liveRegion\n- Severity filter chips have accessibilityRole=\"checkbox\" with checked state\n- Disagreement list items have comprehensive accessibilityLabel descriptions\n- Updated SEVERITY_COLORS for 4.5:1+ contrast ratio on dark backgrounds (#ff8a80, #ffe082, #90caf9)\n- Footer buttons have proper role, label, and hint\n\nResponsive design improvements:\n- Added useWindowDimensions hook to get screen width\n- Grid cells dynamically sized based on screen width and column count\n- Added horizontal ScrollView wrapper for grids that exceed screen width\n- MIN_TOUCH_TARGET constant (44pt) for accessible touch targets\n- GRID_CELL_MIN_SIZE (24) and GRID_CELL_MAX_SIZE (32) constraints\n- tabBarContent style for proper horizontal tab layout\n\nAll acceptance criteria met:\n\u2713 Modal scrolls properly on small screens (vertical ScrollView + horizontal grid scroll)\n\u2713 Grid visualization scales appropriately (dynamic cell sizing based on screen width)\n\u2713 Color contrast meets WCAG AA (4.5:1+ contrast ratios for text colors)\n\u2713 Screen reader labels on interactive elements (comprehensive accessibility props)\n\nCommit: 3cd34e6a",
          "updated_at": "2025-12-22T09:30:06.226885+00:00"
        }
      ]
    }
  ],
  "dependencies": {
    "external": [
      "zod (already installed)",
      "react-native",
      "expo"
    ],
    "internal": [
      "ensembleExtraction.ts",
      "aiExtraction.ts",
      "overlayTypes.ts"
    ]
  },
  "risks": [
    {
      "risk": "Performance impact of storing all raw responses",
      "mitigation": "Make debug mode opt-in via settings, compress or truncate large responses"
    },
    {
      "risk": "Memory usage with multiple large model responses",
      "mitigation": "Lazy load comparison data, clear after modal closes"
    },
    {
      "risk": "UI complexity with many disagreements",
      "mitigation": "Implement filtering, pagination, and progressive disclosure"
    }
  ],
  "services_involved": [
    "pips-solver/src/services/ensembleExtraction.ts",
    "pips-solver/src/services/aiExtraction.ts",
    "pips-solver/src/model/overlayTypes.ts",
    "pips-solver/src/app/components/ExtractionComparisonModal.tsx",
    "pips-solver/src/app/components/AIVerificationModal.tsx",
    "pips-solver/src/app/screens/OverlayBuilderScreen.tsx",
    "pips-solver/src/services/extraction/validation/gridValidator.ts"
  ],
  "final_acceptance": [
    "User can trigger AI extraction with ensemble strategy",
    "After extraction, user sees verification modal with 'Compare Models' option",
    "Comparison modal shows side-by-side results from each model",
    "Disagreements are highlighted with severity indicators",
    "User can navigate between models and see detailed diff summary",
    "Setting exists to enable/disable debug response storage",
    "Performance impact is minimal when debug mode is disabled"
  ],
  "spec_file": "spec.md",
  "qaStatus": {
    "status": "pending",
    "tests_passed": "",
    "issues": ""
  },
  "last_updated": "2025-12-22T09:35:41.883694+00:00",
  "recoveryNote": "Task recovered from stuck state at 2025-12-22T08:09:10.845Z",
  "qa_signoff": {
    "status": "approved",
    "qa_session": 0,
    "issues_found": [
      {
        "description": "None - all acceptance criteria met"
      }
    ],
    "tests_passed": {},
    "timestamp": "2025-12-22T09:35:41.883694+00:00",
    "ready_for_qa_revalidation": false
  }
}